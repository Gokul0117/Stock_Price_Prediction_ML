{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mTM6vM-bDOGf"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_stock_data(ticker, past_days):\n",
        "    try:\n",
        "        # If user gives small number, still fetch full available data\n",
        "        df = yf.download(ticker, period=f\"{int(past_days)}d\")\n",
        "        if df.empty or len(df) < 5:\n",
        "            df = yf.download(ticker, start=\"2010-01-01\")  # fallback full history\n",
        "        return df[['Close']]\n",
        "    except Exception:\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "vM4sQSd0DSAZ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(scaled_data, time_steps):\n",
        "    X, y = [], []\n",
        "    if len(scaled_data) <= time_steps:\n",
        "        # not enough data: duplicate existing data\n",
        "        while len(scaled_data) <= time_steps:\n",
        "            scaled_data = np.concatenate([scaled_data, scaled_data])\n",
        "    for i in range(time_steps, len(scaled_data)):\n",
        "        X.append(scaled_data[i-time_steps:i])\n",
        "        y.append(scaled_data[i])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "P2hgcXSBDSIf"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=input_shape),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# ‚úÖ CNN Model\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv1D(64, 3, activation='relu', input_shape=input_shape),\n",
        "        Flatten(),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZNUu5maDDSO8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_stock(ticker, days):\n",
        "    try:\n",
        "        # Fetch data dynamically\n",
        "        data = yf.download(ticker, period=f\"{days}d\")\n",
        "        if data.empty:\n",
        "            return f\"‚ö†Ô∏è No data found for '{ticker}'. Try a valid ticker.\", None\n",
        "\n",
        "        # Automatically handle very small datasets\n",
        "        if len(data) < 2:\n",
        "          return f\"‚ö†Ô∏è Only one data point found for '{ticker}'. Try at least 2 days.\", None\n",
        "\n",
        "\n",
        "        # Prepare data\n",
        "        df = data[['Close']].copy()\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaled_data = scaler.fit_transform(df)\n",
        "        window = max(2, min(5, len(df)//2))  # dynamic window\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(window, len(scaled_data)):\n",
        "            X.append(scaled_data[i-window:i, 0])\n",
        "            y.append(scaled_data[i, 0])\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "        # Simple LSTM model\n",
        "        model = Sequential([\n",
        "            LSTM(32, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
        "            LSTM(32),\n",
        "            Dense(1)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        model.fit(X, y, epochs=5, batch_size=4, verbose=0)\n",
        "\n",
        "        # Predict next day\n",
        "        last_window = scaled_data[-window:]\n",
        "        last_window = np.reshape(last_window, (1, window, 1))\n",
        "        pred_scaled = model.predict(last_window)\n",
        "        pred = scaler.inverse_transform(pred_scaled)\n",
        "        predicted_value = float(pred[0][0])\n",
        "        last_close = float(df['Close'].iloc[-1])\n",
        "        direction = \"üìà Up\" if predicted_value > last_close else \"üìâ Down\"\n",
        "\n",
        "        # Plot Actual vs Predicted\n",
        "        predicted_all = model.predict(X)\n",
        "        predicted_prices = scaler.inverse_transform(predicted_all)\n",
        "        actual_prices = scaler.inverse_transform(y.reshape(-1, 1))\n",
        "\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(actual_prices, label='Actual', linewidth=2)\n",
        "        plt.plot(predicted_prices, label='Predicted', linestyle='--')\n",
        "        plt.title(f'{ticker} Stock Price Prediction')\n",
        "        plt.xlabel('Days')\n",
        "        plt.ylabel('Price ($)')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        img_path = \"prediction_plot.png\"\n",
        "        plt.savefig(img_path)\n",
        "        plt.close()\n",
        "\n",
        "        return (\n",
        "            f\"‚úÖ Tomorrow Prediction for **{ticker}**\\n\"\n",
        "            f\"Predicted Price: **${predicted_value:.2f}**\\n\"\n",
        "            f\"Current Price: **${last_close:.2f}**\\n\"\n",
        "            f\"Direction: **{direction}**\"\n",
        "        ), img_path\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Error: {str(e)}\", None\n"
      ],
      "metadata": {
        "id": "fRYFRCUzDSYK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ui = gr.Interface(\n",
        "    fn=predict_stock,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter Stock Ticker (e.g., AAPL, TSLA, GOOGL)\"),\n",
        "        gr.Number(label=\"Enter Number of Past Days (e.g., 1, 7, 30, 365, 2000)\")\n",
        "    ],\n",
        "    outputs=[\"text\", \"image\"],\n",
        "    title=\"üìä Real-Time Stock Price Direction Predictor\",\n",
        "    description=\"Enter any stock ticker and any number of days to predict if the next day's price will go Up üìà or Down üìâ\"\n",
        ")\n",
        "\n",
        "ui.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "qBosL-OEFWyK",
        "outputId": "4e2f2064-3c10-4f6e-f1fb-17e8e55ff19b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://06c12c25b0f4df4d5a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://06c12c25b0f4df4d5a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}